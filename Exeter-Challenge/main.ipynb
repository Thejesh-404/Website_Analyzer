{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, urljoin\n",
    "import ngram_value\n",
    "import size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the url :www.exeterpremedia.com\n"
     ]
    }
   ],
   "source": [
    "url = input('Enter the url :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds (http://)  if not included\n",
    "if 'http://' in url or 'https://' in url:\n",
    "    pass\n",
    "else:\n",
    "    url = 'http://' + url    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_name = urlparse(url).netloc   # returns the domain name of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks whether link is valid or not\n",
    "def check_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        #print(\"URL is valid and exists on the Internet\")\n",
    "        return True\n",
    "    except:\n",
    "        #print(\"URL does not exist on the Internet\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the homepage of the web_link\n",
    "def home_page(url):\n",
    "    count = 0\n",
    "    url = url + '/'\n",
    "    url_len = len(url)\n",
    "    for i in range(url_len):\n",
    "        if '/' == url[i]:\n",
    "            count +=1\n",
    "            if count == 3:\n",
    "                break\n",
    "    return i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = home_page(url)\n",
    "url = url[0:val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding all the links \n",
    "\n",
    "valid_link = set()  # set variable to remove duplicate values\n",
    "\n",
    "def link_gen(url):\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(res.text,'lxml')\n",
    "    \n",
    "    for link in soup.find_all('a',href=True):                            # loop through all links\n",
    "        \n",
    "        first_char = link['href'][0]\n",
    "        \n",
    "        if (check_url(link['href']) and  '#' not in link['href'][0]):    # excluding garbage link\n",
    "            if first_char != '/':\n",
    "                valid_link.add(link['href'])\n",
    "                \n",
    "        \n",
    "        if first_char == '/':                                            # adding url to few internal link                                      \n",
    "            final_link = url + link['href']\n",
    "            valid_link.add(final_link)\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_gen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_num = len(valid_link)  # no of valid links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary list variables to store data in csv\n",
    "\n",
    "internal_links = []\n",
    "external_links = []\n",
    "\n",
    "title_tag = []\n",
    "meta_value = []\n",
    "internal_value = []\n",
    "external_value = []\n",
    "uni_value = []\n",
    "bi_value = []\n",
    "size_value = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_title(valid_link):\n",
    "    \n",
    "    for link in valid_link:                                 # looping through all valid link\n",
    "        \n",
    "        try:\n",
    "            res = requests.get(link)                        # try except block if it throws error\n",
    "            soup = bs4.BeautifulSoup(res.text,'lxml')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if len(soup.select('title')) != 0:                 # selecting title of the webpage and storing it in list\n",
    "            title_tag.append(soup.select('title')[0].text)\n",
    "        else:\n",
    "            title_tag.append('N/A')\n",
    "        \n",
    "        \n",
    "        description = soup.find('meta', attrs={'name':'og:description'}) or soup.find('meta', attrs={'property':'description'}) or soup.find('meta', attrs={'name':'description'})\n",
    "        if description:                                   # adding desc from meta tag to list\n",
    "           description_text = description.get('content')\n",
    "        else:\n",
    "            description_text = 'N/A'\n",
    "            \n",
    "        meta_value.append(description_text)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if domain_name in link:                           # classfying the internal and external links                      \n",
    "            internal_links.append(link)\n",
    "            internal_value.append('yes')\n",
    "            external_value.append('no')\n",
    "        else:\n",
    "            external_links.append(link)\n",
    "            internal_value.append('no')\n",
    "            external_value.append('yes')\n",
    "        \n",
    "        a,b = ngram_value.uni_bi_values(link)            # appending unigrams,bigrams\n",
    "        uni_value.append(a)\n",
    "        bi_value.append(b)\n",
    "        \n",
    "        \n",
    "        temp = size.total_size(link)                    # adding size of the web page to list\n",
    "        size_value.append(temp)\n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title(valid_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid_link = list(valid_link)   # set to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = {}\n",
    "\n",
    "for i in range(valid_num):         # looping through each valid link and storing coresponding values\n",
    "    \n",
    "    final_result[i] = [new_valid_link[i],title_tag[i],meta_value[i],internal_value[i],external_value[i],uni_value[i],bi_value[i],size_value[i]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_df = pd.DataFrame.from_dict(final_result,orient='index', columns=['Links','Title','Meta-data(DESC)','Internal','External','unigram','bi-gram','web-page size(KB)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Links</th>\n",
       "      <th>Title</th>\n",
       "      <th>Meta-data(DESC)</th>\n",
       "      <th>Internal</th>\n",
       "      <th>External</th>\n",
       "      <th>unigram</th>\n",
       "      <th>bi-gram</th>\n",
       "      <th>web-page size(KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>https://www.linkedin.com/feed/hashtag/?keyword...</td>\n",
       "      <td>Sign Up | LinkedIn</td>\n",
       "      <td>500 million+ members | Manage your professiona...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>[Services, We, services, US, us, publishers, E...</td>\n",
       "      <td>[(Personal, Information), (Exeter, Premedia), ...</td>\n",
       "      <td>24.3701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>https://www.exeterpremedia.com/contact-us/</td>\n",
       "      <td>Exeter - Contact Us</td>\n",
       "      <td>Reach us at ravi@exeterpremedia.com and +91-44...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>[Services, services, We, US, us, publishers, E...</td>\n",
       "      <td>[(Personal, Information), (Exeter, Premedia), ...</td>\n",
       "      <td>104.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>https://www.exeterpremedia.com/wp-content/uplo...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>[Services, services, We, US, us, publishers, E...</td>\n",
       "      <td>[(Personal, Information), (Exeter, Premedia), ...</td>\n",
       "      <td>4.67578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>http://www.exeterpremedia.com/services/#Editor...</td>\n",
       "      <td>Exeter - Services</td>\n",
       "      <td>Exeter provides editorial services such copyed...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>[Services, services, We, US, us, publishers, E...</td>\n",
       "      <td>[(Personal, Information), (Exeter, Premedia), ...</td>\n",
       "      <td>126.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>https://www.exeterpremedia.com/wp-content/uplo...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>[Services, services, We, US, us, publishers, E...</td>\n",
       "      <td>[(Personal, Information), (Exeter, Premedia), ...</td>\n",
       "      <td>8.20508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Links                Title  \\\n",
       "80  https://www.linkedin.com/feed/hashtag/?keyword...   Sign Up | LinkedIn   \n",
       "81         https://www.exeterpremedia.com/contact-us/  Exeter - Contact Us   \n",
       "82  https://www.exeterpremedia.com/wp-content/uplo...                  N/A   \n",
       "83  http://www.exeterpremedia.com/services/#Editor...    Exeter - Services   \n",
       "84  https://www.exeterpremedia.com/wp-content/uplo...                  N/A   \n",
       "\n",
       "                                      Meta-data(DESC) Internal External  \\\n",
       "80  500 million+ members | Manage your professiona...       no      yes   \n",
       "81  Reach us at ravi@exeterpremedia.com and +91-44...      yes       no   \n",
       "82                                                N/A      yes       no   \n",
       "83  Exeter provides editorial services such copyed...      yes       no   \n",
       "84                                                N/A      yes       no   \n",
       "\n",
       "                                              unigram  \\\n",
       "80  [Services, We, services, US, us, publishers, E...   \n",
       "81  [Services, services, We, US, us, publishers, E...   \n",
       "82  [Services, services, We, US, us, publishers, E...   \n",
       "83  [Services, services, We, US, us, publishers, E...   \n",
       "84  [Services, services, We, US, us, publishers, E...   \n",
       "\n",
       "                                              bi-gram web-page size(KB)  \n",
       "80  [(Personal, Information), (Exeter, Premedia), ...           24.3701  \n",
       "81  [(Personal, Information), (Exeter, Premedia), ...           104.938  \n",
       "82  [(Personal, Information), (Exeter, Premedia), ...           4.67578  \n",
       "83  [(Personal, Information), (Exeter, Premedia), ...            126.92  \n",
       "84  [(Personal, Information), (Exeter, Premedia), ...           8.20508  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_df.tail(5)    #printing Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_df.to_csv('exeter.csv')    #downloading csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Top level pages: 85\n"
     ]
    }
   ],
   "source": [
    "print('No of Top level pages: ' + str(valid_num))  # total top level pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Internal links: 51\n"
     ]
    }
   ],
   "source": [
    "print('No of Internal links: ' + str(len(internal_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Internal links: 34\n"
     ]
    }
   ],
   "source": [
    "print('No of Internal links: ' + str(len(external_links)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
